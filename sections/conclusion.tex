%% LaTeX2e class for student theses
%% sections/conclusion.tex
%% 
%% Karlsruhe Institute of Technology
%% Institute for Program Structures and Data Organization
%% Chair for Software Design and Quality (SDQ)
%%
%% Dr.-Ing. Erik Burger
%% burger@kit.edu
%%
%% Version 1.4, 2023-06-19

\chapter{Conclusion}
\label{ch:Conclusion}

The general performance impacts of TDX are so small that they can be mostly ignored in day-to-day applications. Most users will not notice any differences, especially if memory encryption is used anyway. Comparing hosting on your own hardware, hosting in the cloud with TDX and hosting in the cloud without TDX, only about 10\% calculation time differences are to be expected. Bigger improvements could be made if a platform that does not need an additional VM layer can be made available, this could improve calculation speeds up to 30\%. There are however certain scenarios that could lead to a much higher overhead. As shown in \cref{performance} some instructions or methods can experience significant slowdowns when using TDX. It is unclear what leads to these slowdowns so the developer needs to check for themselves if they experience some unexplainable slow execution speeds.

These small performance decreases can potentially buy some great security guarantees, especially against software based attacks from a malicious Host or similar. TDX attestation, if implemented properly, seems to be found in its security assumptions. The threat model considers anyone with hardware access as untrusted, this includes the cloud provider. As discussed previously TDX can not protect against all hardware attacks, meaning that anyone with hardware access can extract information from a TD if they know how to implement certain kinds of attacks, discussed in \cref{Security Analysis}. Similarly someone with hardware access can also extract information on self-hosted applications. The assumption that the cloud provider can be completely removed from the list of trusted parties, as claimed by Intel, is thus at best an exaggeration and at worst just false. Looking further into one implementation of Intel TDX these issues become even more pronounced, a lot of trust has to be put into Microsoft proprietary code regarding the attestation. It was not possible for me to create a quote that was completely independent of any Microsoft code. As it stands currently it is not recommended to rely upon TDX, to remove the cloud provider from the list of trusted parties.


\myparagraph{Outlook}

This thesis focused on simple TDX implementations. With TDX having just been released, most of those implementations are still in their infancy and problems are to be expected. Hopefully in the future some of those, that have been highlighted in this thesis and those that have not been will be fixed. Nonetheless there are still additional things that can be looked at. The implementation of TDX in Ubuntu 22 appears to cause instability issues and also performance defiencies compared to the implementation in Ubuntu 23. Having a deeper look at the differences between those two could grant significant improvements. Additionally, comparisons between the different hardware Confidential Computing hardware providers are necessary to being able to make the decision for or against Confidential Computing. Additionally looking into the implementation of PyTorch to figure out why its copy function experiences such significant slowdown is advised. 

For the future Intel has planned a cooperation with Nvidia to bring Confidential Computing and AI closer together \url{https://community.intel.com/t5/Blogs/Products-and-Solutions/Security/Intel-Nvidia-Collaborate-to-Deliver-Confidential-AI-Solutions/post/1500066}. With the release of Intel attestation for Nvidia hardware to be planned in the first half of 2024, confidential computing on GPU hardware could be a possibility. Intel and Nvidia have yet to release architecture specifications for their collaboration but their security promises and assumptions will have to be tested then. If implementation could be simplified for the average user this could be a great step into the right direction for data security. The dangers of dedicated GPUs and the possible performance losses with establishing a secure communication between CPU and GPU are a challenge that will have to be solved first. Silberstein et al. highlighted the dangers of insecure communication and other problems with dedicated GPUs in their 2020 paper \cite{zhu_enabling_2020}. All of these improvements and collaborations are only nice to have as long as the issues outlined in this thesis are not remedied.

Additionally this thesis was limited in regard to the amount of performancetesting that was feasible. More I/O heavy workloads and even some GPU-bound workloads could be tested. Implementing ways to calculate on a non-trusted GPU, while maintaining data confidentiality is still an ongoing line of research, which could be even more interesting in the future, but it still has security and performance problems, compare \cite{ogburn_homomorphic_2013} and \cite{li_security_2020} for more information on this.

